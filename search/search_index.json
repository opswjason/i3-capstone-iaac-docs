{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Pathways SRE \u2013 Capstone Project","text":"<p>Infrastructure-as-Code: Deploy and Operate</p>"},{"location":"#learning-objectives","title":"Learning Objectives","text":"<ul> <li>Create automations for deploying infrastructure, platform, and application using an Infrastructure-as-Code approach.</li> <li>Learn how to configure alert rules and send notifications for critical incidents.</li> <li>Simulate operational activities and incidents by intentionally introducing failures, and write operations runbooks to resolve them.</li> <li>Write operations runbooks to resolve them.</li> </ul>"},{"location":"#case-description","title":"Case Description","text":"<p>Build automation that deploys infrastructure hosted in AWS using Infrastructure-as-Code. In the event of a catastrophic infrastructure outage, the automation must be able to rebuild a similarly configured infrastructure from the ground up by simply running it. Once the infrastructure is up, a highly available web app must be deployed on top, complete with monitoring and logging.</p> <p>Runbooks must be written to resolve common incidents.</p> <p>All related documentation must be in the given GitHub repository.</p>"},{"location":"#limitations","title":"Limitations","text":"<ul> <li>KodeKloud\u2019s AWS playground will be used to deploy the infrastructure. The playground will only be active for 3 hours and will be destroyed automatically after.</li> <li>Directly pushing or committing to the GitHub repository is not allowed. Pull requests with review, approval, and merging must be practiced for collaboration purposes.</li> <li>On the day of the defense, it is expected that the infrastructure will be freshly re-deployed using the created automation.</li> </ul>"},{"location":"#prerequisites","title":"Prerequisites","text":""},{"location":"#co-trainees","title":"c/o Trainees:","text":"<ul> <li>Create GitHub accounts using OpsWerks email.</li> <li>Send the list of GitHub accounts to the course admin.</li> </ul>"},{"location":"#co-course-admins","title":"c/o Course Admins:","text":"<ul> <li>Create a private GitHub repo and give write access to trainees.</li> </ul>"},{"location":"#solution-must-haves","title":"Solution Must-Haves","text":""},{"location":"#infra-as-code-for-deploying-the-infrastructure","title":"Infra-as-code for deploying the infrastructure:","text":""},{"location":"#automation-requirements","title":"Automation requirements","text":"<ul> <li>Must cover the deployment of AWS infrastructure (creation of AWS objects) as well as configuration.</li> <li>Must cover the deployment of a container orchestration platform on top of the infrastructure (Kubernetes).</li> <li>Can be created with combinations of scripts, Jenkins pipelines, or Ansible playbooks.</li> </ul>"},{"location":"#infrastructure-requirements","title":"Infrastructure Requirements","text":"<ul> <li>A Kubernetes cluster must be deployed for running the web app.</li> <li>Splunk must be deployed as the logging solution.</li> <li>Prometheus must be deployed as the monitoring solution.</li> <li>AlertManager must be deployed as the alerting solution.</li> </ul>"},{"location":"#web-app","title":"Web App","text":""},{"location":"#deployment","title":"Deployment","text":"<ul> <li>The web app of your own choosing must be accessible on the internet via IP or hostname.</li> <li>A Jenkins pipeline must be in place for deploying an updated build of the app to the Kubernetes cluster.</li> </ul>"},{"location":"#operation","title":"Operation","text":"<ul> <li>Web app logs must be stored in Splunk.</li> <li>Web app related telemetry must be scraped by Prometheus.</li> <li>Email notification must be in place for any infrastructure-related and web app-related alerts.</li> </ul>"},{"location":"#version-control-git-and-github","title":"Version Control: Git and GitHub","text":"<ul> <li>The given GitHub repository is the main storage for all project info: from the automation codebase, infrastructure configurations, to documentation.</li> <li>To show that pull request practices were strictly followed, the main repository\u2019s commit history must only consist of merged pull requests.</li> </ul>"},{"location":"#ops-simulation","title":"Ops Simulation","text":""},{"location":"#introduce-failures-in-your-infrastructure-and-application-based-on-but-not-limited-to-the-alerting-rules-required","title":"Introduce failures in your infrastructure and application based on (but not limited to) the alerting rules required:","text":"<ul> <li>Infrastructure failures<ul> <li>Down Kubernetes Control Plane / Worker node.</li> <li>Down EC2 instances.</li> <li>Entire infrastructure is compromised and needs to be rebuilt.</li> </ul> </li> <li>Application failures<ul> <li>Web app is down.</li> <li>Too many 4xx and 5xx HTTP errors.</li> </ul> </li> <li>Create respective runbooks to properly diagnose, address, and resolve these incidents.</li> </ul>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#the-following-must-be-included","title":"The following must be included:","text":"<ul> <li>Project documentation<ul> <li>Description of the solution.</li> <li>An architecture diagram of how the solution works, showing the technologies used in the solution stack.</li> </ul> </li> <li>Ops Runbook<ul> <li>How to resolve common infra-related outages.</li> <li>How to resolve common app-related outages.</li> <li>Disaster recovery plan for rebuilding infrastructure using the automation.</li> </ul> </li> </ul>"},{"location":"about/","title":"About  the  Authors","text":""},{"location":"about/#pathways-sre-program-intake-3-team","title":"Pathways  SRE  Program  -  Intake  3  Team","text":"<p>Our  team,  Pathways  SRE  Program  -  Intake  3,  is  a  diverse  group  of professionals  passionate  about  Site  Reliability  Engineering  (SRE)  and  cloud  infrastructure.  Together,  we\u2019ve  brought  a  wide  range  of  skills  and  experiences  to  this  capstone  project,  ensuring  a  comprehensive solution.</p>"},{"location":"about/#team-members","title":"Team  Members:","text":"<ul> <li>Arlene Larisma (CEBU) </li> <li>Sean Yutiampo (CEBU)</li> <li>Jason Andico (MNL)</li> </ul>"},{"location":"about/#our-journey","title":"Our  Journey","text":"<p>As  part  of  the  Pathways  SRE  Program,  we  have  undergone  rigorous  training  and  hands-on  projects  that  have  honed  our  skills  in  SRE  principles.  This  capstone  project  is  the  culmination  of  our  learning  and  collaboration,  reflecting  our  commitment  to innovation  in  cloud  infrastructure  management.</p> <p>We  are  proud  of  what  we  have  achieved  and  excited  to  share  our  work.  Thank  you  for  exploring  our  capstone  project! </p>"},{"location":"diagram-examples/","title":"Diagram Examples","text":""},{"location":"diagram-examples/#flowcharts","title":"Flowcharts","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Failure?};\n  B --&gt;|Yes| C[Investigate...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Success!];</code></pre>"},{"location":"diagram-examples/#sequence-diagrams","title":"Sequence Diagrams","text":"<pre><code>sequenceDiagram\n  autonumber\n  Server-&gt;&gt;Terminal: Send request\n  loop Health\n      Terminal-&gt;&gt;Terminal: Check for health\n  end\n  Note right of Terminal: System online\n  Terminal--&gt;&gt;Server: Everything is OK\n  Terminal-&gt;&gt;Database: Request customer data\n  Database--&gt;&gt;Terminal: Customer data</code></pre>"},{"location":"solution/","title":"Our Solution","text":"<p>The proposed architecture leverages a blend of AWS services and DevOps tools to ensure an efficient, scalable, and robust environment for the weather application. This setup not only supports continuous integration and deployment but also enhances monitoring and logging, ensuring high availability and performance. Below is an in-depth look into each component and how they interconnect to deliver a seamless operational environment.</p>"},{"location":"solution/#architecture-overview","title":"Architecture Overview","text":"<p>The diagram outlines the AWS infrastructure setup for a weather application, utilizing various AWS services and DevOps tools. </p> <p>Here's the breakdown</p>"},{"location":"solution/#source-code-management-and-cicd-pipeline","title":"Source Code Management and CI/CD Pipeline","text":"<ul> <li> <p>GitHub: Stores the source code for the weather application.</p> </li> <li> <p>Jenkins: Handles continuous integration and deployment (CI/CD). It triggers deployments and runs tests.</p> </li> <li> <p>Ansible: Used for configuration management and automation, deploying and configuring the application on different environments.</p> </li> </ul>"},{"location":"solution/#aws-codebuild-and-aws-cloudformation","title":"AWS CodeBuild and AWS CloudFormation","text":"<ul> <li> <p>AWS CodeBuild: Builds and tests the application, triggered by AWS CloudFormation.</p> </li> <li> <p>AWS CloudFormation: Provisions and manages AWS resources using our custom templates, triggering deployments to AWS CodeBuild.</p> </li> </ul>"},{"location":"solution/#amazon-eks-elastic-kubernetes-service","title":"Amazon EKS (Elastic Kubernetes Service)","text":"<ul> <li> <p>EKS Clusters: Deployed in us-east-1 and us-west-2 regions as both were the only supported regions in  KodeKloud Playground.</p> </li> <li> <p>VPC: Clusters are within a Virtual Private Cloud (VPC) for network isolation and security.</p> </li> <li> <p>Pods: The weather application runs inside Kubernetes pods on these EKS clusters.</p> </li> </ul>"},{"location":"solution/#amazon-s3","title":"Amazon S3","text":"<ul> <li> <p>Regions: S3 buckets in us-east-1 and us-west-2 for storing application data and backups.</p> </li> <li> <p>Backup and Restore: Data backed up from us-east-1 to us-west-2 using Velero for backup and restore operations.</p> </li> </ul>"},{"location":"solution/#monitoring-and-logging","title":"Monitoring and Logging","text":"<ul> <li>Prometheus: Monitors the application and collects metrics.</li> <li>Grafana: Visualizes metrics collected by Prometheus.</li> <li>Splunk: Logs and analyzes application logs.</li> </ul> <p>This comprehensive setup ensures efficient deployment, management, and monitoring of the weather application using AWS and popular DevOps tools.</p>"},{"location":"eks/eks-setup-using-ansible/","title":"Automated EKS Cluster setup with Ansible Guide","text":"<p>This README demonstrates the deployment of a Private EKS Cluster with High Availability using Ansible and Amazon Cloudformation.</p>"},{"location":"eks/eks-setup-using-ansible/#prerequisites","title":"Prerequisites","text":"<ul> <li>Ansible: Make sure you have Ansible installed on your local machine.</li> <li>AWS Access Key: This is your AWS credentials which consists of Access Key ID and a Secret Access Key, that allow you to authenticate and interact with AWS services</li> <li>Python: Python is need in order to run Ansible. Make sure to install it.</li> </ul>"},{"location":"eks/eks-setup-using-ansible/#installation","title":"Installation","text":"<ol> <li>Clone the repository:    <pre><code>git clone &lt;repository_url&gt;\ncd &lt;repository_name&gt;\n</code></pre></li> <li>Navigate to the ansible directory:    <pre><code>cd ansible\n</code></pre></li> </ol>"},{"location":"eks/eks-setup-using-ansible/#eks-cluster-setup-with-ansible","title":"EKS Cluster Setup with Ansible","text":"<ul> <li> <p>To create the EKS cluster, execute the following Ansible playbook:    <pre><code>ansible-playbook deploy_HAcluster.yml\n</code></pre></p> </li> <li> <p>After the EKS cluster has been created, configure the cluster to join the Worker Nodes to the cluster:    <pre><code>ansible-playbook -i inventory/inventory.ini configure_HAcluster.yml\n</code></pre></p> </li> <li> <p>Finally, test the EKS cluster by deploying pods to the cluster:    <pre><code>ansible-playbook -i inventory/inventory.ini test_HAcluster.yml\n</code></pre></p> </li> </ul>"},{"location":"eks/eks-setup-using-ansible/#aws-templates","title":"AWS Templates","text":"<p>The aws/templates directory contains CloudFormation templates for setting up the necessary AWS resources:</p> <ul> <li>bastion.yml: Provisions a Bastion host for secure access.</li> <li>eks.yml:eks.yml: Creates the EKS cluster.</li> <li>network.yml:network.yml: Configures networking resources like VPC and subnets.</li> <li>roles.yml:roles.yml: Defines IAM roles for the EKS cluster.</li> </ul>"},{"location":"eks/eks-setup-using-ansible/#testing","title":"Testing","text":"<p>When the cluster has been created, you may test your setup. First is to ssh to your Bastion-Host and run the following command to verify if have access to the cluster and the Nodes are joined in your cluster:   <code>bash    kubectl get node</code></p>"},{"location":"monitoring-and-observability/monitoring/","title":"Helm Chart Installation Guide","text":"<p>This README provides instructions for installing MySQL, Prometheus, and Grafana using Helm charts. This setup assumes you have Helm installed and configured in your Kubernetes cluster.</p>"},{"location":"monitoring-and-observability/monitoring/#prerequisites","title":"Prerequisites","text":"<ol> <li>Kubernetes cluster</li> <li>Helm installed and configured</li> <li>Access to Docker Registry</li> </ol>"},{"location":"monitoring-and-observability/monitoring/#installation-steps","title":"Installation Steps","text":""},{"location":"monitoring-and-observability/monitoring/#1-install-mysql","title":"1. Install MySQL","text":"<p>To install MySQL with specific configurations, run the following command:</p> <p><pre><code>helm install mysql oci://registry-1.docker.io/bitnamicharts/mysql \\\n    --set auth.username=grafana \\\n    --set auth.password=grafana \\\n    --set auth.database=grafana\n</code></pre> For more options and detailed configurations, please refer to the https://artifacthub.io/packages/helm/bitnami/mysql.</p> <pre><code>Configuration Parameters:\n\nauth.username: The username for MySQL (set to grafana).\nauth.password: The password for MySQL (set to grafana).\nauth.database: The database name to create (set to grafana).\n</code></pre>"},{"location":"monitoring-and-observability/monitoring/#2-install-prometheus","title":"2. Install Prometheus","text":"<p>To install Prometheus, execute the following command:</p> <pre><code>helm install prometheus prometheus.tgz \\\n    --set webapp= \\\n    --set basicauth.user= \\\n    --set basicauth.password=\n</code></pre> <p>Configuration Parameters:</p> <p>webapp: The web application URL (leave empty if not used). basicauth.user: Basic authentication username (leave empty if not used). basicauth.password: Basic authentication password (leave empty if not used).</p>"},{"location":"monitoring-and-observability/monitoring/#3-install-grafana","title":"3. Install Grafana","text":"<p>To install Grafana and connect it to the Prometheus and MySQL instances, run:</p> <p><pre><code>helm install grafana grafana.tgz \\\n    --set prometheus.svc=prometheus \\\n    --set prometheus.namespace=default \\\n    --set prometheus.port=9090 \\\n    --set mysql.svc=mysql \\\n    --set mysql.namespace=default \\\n    --set mysql.port=3306 \\\n    --set mysql.user=grafana \\\n    --set mysql.password=grafana\n</code></pre> Configuration Parameters:</p> <p>prometheus.svc: The service name for Prometheus (set to prometheus). prometheus.namespace: The namespace for Prometheus (set to default). prometheus.port: The port for Prometheus (set to 9090). mysql.svc: The service name for MySQL (set to mysql). mysql.namespace: The namespace for MySQL (set to default). mysql.port: The port for MySQL (set to 3306). mysql.user: The MySQL username (set to grafana). mysql.password: The MySQL password (set to grafana).  </p>"},{"location":"monitoring-and-observability/monitoring/#accessing-the-applications","title":"Accessing the Applications","text":"<p>After installation, you can access the applications as follows:</p> <p>MySQL: Connect using a MySQL client with the credentials specified. Prometheus: Access Prometheus at http://:9090. Grafana: Access Grafana at http://:3000 (default port). Use the MySQL credentials to connect to the database."},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/","title":"How to add datasources grafana","text":""},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#adding-data-sources-with-extra-volumes-for-grafana","title":"Adding Data Sources with Extra Volumes for Grafana","text":"<p>You can set up data sources in Grafana using extraVolumes and extraVolumeMounts. This allows you to create a ConfigMap for your data sources and mount it into the Grafana pod without modifying the main values.yaml.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#steps-to-configure-data-sources","title":"Steps to Configure Data Sources","text":"<ol> <li>Create a ConfigMap for Data Sources First, create a ConfigMap containing your data source configurations. Here\u2019s an example of how to create a ConfigMap named grafana-datasources:</li> </ol> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-datasources\n  namespace: &lt;your-namespace&gt;\ndata:\n  datasource.yml: |\n    apiVersion: 1\n    datasources:\n      - name: Prometheus\n        type: prometheus\n        access: proxy\n        url: http://prometheus-server.&lt;your-namespace&gt;:9090\n        jsonData:\n          tlsSkipVerify: true\n</code></pre> <ol> <li> <p>Save this as datasources-configmap.yaml, and create it with: <pre><code>kubectl apply -f datasources-configmap.yaml\n</code></pre></p> </li> <li> <p>Create a Separate Values File for Data Sources Create another values file named datasources-values.yaml. Here\u2019s an example configuration to specify the extra volumes and mounts:</p> </li> </ol> <pre><code>extraVolumes:\n  - name: datasources\n    configMap:\n      name: grafana-datasources\n\nextraVolumeMounts:\n  - name: datasources\n    mountPath: /etc/grafana/provisioning/datasources\n    readOnly: true\n</code></pre> <ol> <li>Deploy or Update Grafana To deploy Grafana with the data source configuration, use the following command, ensuring you pass both the main values.yaml and the datasources-values.yaml:</li> </ol> <pre><code>helm install grafana grafana/grafana -f values.yaml -f datasources-values.yaml -n &lt;your-namespace&gt;\n</code></pre> <p>If you are updating an existing deployment, use:</p> <pre><code>helm upgrade grafana grafana/grafana -f values.yaml -f datasources-values.yaml -n &lt;your-namespace&gt;\n</code></pre> <ol> <li>Verify the Deployment After deployment, check that Grafana is running and that the data sources are configured correctly. You can view the logs of the Grafana pod to ensure that the data sources were loaded:</li> </ol> <pre><code>kubectl logs &lt;grafana-pod-name&gt; -n &lt;your-namespace&gt;\n</code></pre> <ol> <li>Access the Grafana UI To access the Grafana UI, you can port-forward as before:</li> </ol> <pre><code>kubectl port-forward svc/grafana -n &lt;your-namespace&gt; 3000:80\n</code></pre> <p>Visit http://localhost:3000 to view and manage your data sources under the \"Data Sources\" section.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#additional-notes","title":"Additional Notes","text":"<p>Ensure your data source configurations are correctly formatted in the ConfigMap. For more details on creating and configuring data sources, refer to the Grafana documentation. You can create multiple ConfigMaps for different data sources and mount them similarly by adjusting the extraVolumes and extraVolumeMounts in additional values files.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#dding-dashboards-with-extra-volumes-in-grafana","title":"dding Dashboards with Extra Volumes in Grafana","text":"<p>You can set up Grafana dashboards using extraVolumes and extraVolumeMounts. This allows you to create a ConfigMap for your dashboards and mount it into the Grafana pod without modifying the main values.yaml.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#steps-to-configure-dashboards","title":"Steps to Configure Dashboards","text":"<ol> <li>Create a ConfigMap for Dashboards First, create a ConfigMap containing your Grafana dashboards. Here\u2019s an example of how to create a ConfigMap named grafana-dashboards:</li> </ol> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: grafana-dashboards\n  namespace: &lt;your-namespace&gt;\ndata:\n  example-dashboard.json: |\n    {\n      \"annotations\": {\n        \"list\": []\n      },\n      \"panels\": [\n        {\n          \"datasource\": \"Prometheus\",\n          \"type\": \"graph\",\n          \"title\": \"CPU Usage\",\n          \"targets\": [\n            {\n              \"expr\": \"sum(rate(container_cpu_usage_seconds_total[5m])) by (instance)\",\n              \"format\": \"time_series\"\n            }\n          ]\n        }\n      ],\n      \"schemaVersion\": 16,\n      \"version\": 1\n    }\n</code></pre> <ol> <li> <p>Save this as dashboards-configmap.yaml and create it with: <pre><code>kubectl apply -f dashboards-configmap.yaml\n</code></pre></p> </li> <li> <p>Create a Separate Values File for Dashboards Create another values file named dashboards-values.yaml. Here\u2019s an example configuration to specify the extra volumes and mounts:</p> </li> </ol> <pre><code>extraVolumes:\n  - name: dashboards\n    configMap:\n      name: grafana-dashboards\n\nextraVolumeMounts:\n  - name: dashboards\n    mountPath: /var/lib/grafana/dashboards\n    readOnly: true\n</code></pre> <ol> <li>Deploy or Update Grafana To deploy Grafana with the dashboard configuration, use the following command, ensuring you pass both the main values.yaml and the dashboards-values.yaml:</li> </ol> <pre><code>helm install grafana grafana/grafana -f values.yaml -f dashboards-values.yaml -n &lt;your-namespace&gt;\n</code></pre> <p>If you are updating an existing deployment, use: <pre><code>helm upgrade grafana grafana/grafana -f values.yaml -f dashboards-values.yaml -n &lt;your-namespace&gt;\n</code></pre></p> <ol> <li>Verify the Deployment After deployment, check that Grafana is running and that the dashboards are configured correctly. You can view the logs of the Grafana pod to ensure that the dashboards were loaded:</li> </ol> <pre><code>kubectl logs &lt;grafana-pod-name&gt; -n &lt;your-namespace&gt;\n</code></pre> <ol> <li>Access the Grafana UI To access the Grafana UI, you can port-forward as follows:</li> </ol> <pre><code>kubectl port-forward svc/grafana -n &lt;your-namespace&gt; 3000:80\n</code></pre> <p>Visit http://localhost:3000 to view the dashboards.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#additional-notes_1","title":"Additional Notes","text":"<p>Ensure your dashboard JSON is correctly formatted in the ConfigMap. For details on dashboard configuration, refer to the Grafana documentation.</p> <p>You can create multiple ConfigMaps for different sets of dashboards and mount them similarly by adjusting the extraVolumes and extraVolumeMounts in additional values files.</p>"},{"location":"monitoring-and-observability/grafana/how_to_add_datasources_grafana/#conclusion","title":"Conclusion","text":"<p>You have successfully configured dashboards and data sources for your Grafana setup by using a separate values file for extraVolumes and extraVolumeMounts, allowing for greater flexibility and management of both dashboards and data source configurations through ConfigMaps.</p> <p>Feel free to make any further adjustments or ask if you need more modifications!</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/","title":"Prometheus Pod Configuration","text":"<p>This guide will help you configure your Prometheus pod by passing a custom <code>prometheus.yml</code> configuration file using a values file.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#overview","title":"Overview","text":"<p>In this setup, we will use a Helm chart to deploy Prometheus. The main configuration for Prometheus is specified in a values file, where the configuration keys are nested under the <code>config</code> key. All keys under <code>config</code> will be treated as part of the <code>prometheus.yml</code> file.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#prerequisites","title":"Prerequisites","text":"<ul> <li>Helm installed and configured</li> <li>Kubernetes cluster set up</li> <li>Access to the Kubernetes namespace where Prometheus will be deployed</li> </ul>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#steps-to-configure-prometheus","title":"Steps to Configure Prometheus","text":"<ol> <li>Create Your Values File</li> </ol> <p>Create a yaml file. This file will contain the configuration settings for Prometheus. Here\u2019s an example of how to structure it:</p> <p>```yaml    config:      global:        scrape_interval: 15s        evaluation_interval: 15s      scrape_configs:        - job_name: 'kubernetes'          kubernetes_sd_configs:            - role: pod</p> <p>In this example, we define global settings and a scrape configuration for Kubernetes.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#additional-notes","title":"Additional Notes","text":"<p>You can extend the configuration in values.yaml by adding more keys under the config section as needed for your specific use case. For more complex configurations, refer to the Prometheus documentation for a complete list of available options.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#adding-alerts-with-extra-volumes","title":"Adding Alerts with Extra Volumes","text":"<p>You can also set up alerts by using <code>extraVolumes</code> and <code>extraVolumeMounts</code>. This allows you to create a ConfigMap for your alert rules and mount it into the Prometheus pod without modifying the main <code>values.yaml</code>.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#steps-to-configure-alerts","title":"Steps to Configure Alerts","text":"<ol> <li>Create a ConfigMap for Alerts</li> </ol> <p>First, create a ConfigMap containing your alert rules. Here\u2019s an example of how to create a ConfigMap named <code>prometheus-alerts</code>:</p> <p><code>yaml    apiVersion: v1    kind: ConfigMap    metadata:      name: prometheus-alerts      namespace: &lt;your-namespace&gt;    data:      alerts.yml: |        groups:        - name: example_alerts          rules:          - alert: HighCPUUsage            expr: sum(rate(container_cpu_usage_seconds_total[5m])) by (instance) &gt; 0.8            for: 5m            labels:              severity: warning            annotations:              summary: \"High CPU Usage Detected\"              description: \"CPU usage is above 80% for more than 5 minutes.\"</code></p> <p>Save this as alerts-configmap.yaml, and create it with:</p> <p><pre><code>kubectl apply -f alerts-configmap.yaml\n</code></pre> 2. Create a Separate Values File for Alerts Create another values file named alerts-values.yaml. Here\u2019s an example configuration to specify the extra volumes and mounts:</p> <pre><code>extraVolumes:\n  - name: alerts\n    configMap:\n      name: prometheus-alerts\n\nextraVolumeMounts:\n  - name: alerts\n    mountPath: /etc/prometheus/alerts\n    readOnly: true\n</code></pre> <ol> <li>Deploy or Update Prometheus To deploy Prometheus with the alert configuration, use the following command, ensuring you pass both the main values.yaml and the alerts-values.yaml:</li> </ol> <pre><code>helm install prometheus prometheus-community/prometheus -f values.yaml -f alerts-values.yaml -n &lt;your-namespace&gt;\n</code></pre> <p>If you are updating an existing deployment, use:</p> <pre><code>helm upgrade prometheus prometheus-community/prometheus -f values.yaml -f alerts-values.yaml -n &lt;your-namespace&gt;\n</code></pre> <ol> <li>Verify the Deployment After deployment, check that Prometheus is running and that the alerts are configured correctly. You can view the logs of the Prometheus pod to ensure that the alerts were loaded:</li> </ol> <pre><code>kubectl logs &lt;prometheus-pod-name&gt; -n &lt;your-namespace&gt;\n</code></pre> <ol> <li>Access the Prometheus UI To access the Prometheus UI, you can port-forward as before:</li> </ol> <pre><code>kubectl port-forward svc/prometheus-server -n &lt;your-namespace&gt; 9090:80\n</code></pre> <p>Visit http://localhost:9090 to view the alerts under the \"Alerts\" tab.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#additional-notes_1","title":"Additional Notes","text":"<p>Ensure your alert rules are correctly formatted in the ConfigMap. For details on alert rule configuration, refer to the Prometheus alerting documentation. You can create multiple ConfigMaps for different sets of alerts and mount them similarly by adjusting the extraVolumes and extraVolumeMounts in additional values files.</p>"},{"location":"monitoring-and-observability/prometheus/how_to_configure_prometheus/#conclusion","title":"Conclusion","text":"<p>You have successfully configured alerts for your Prometheus setup using a separate values file for extraVolumes and extraVolumeMounts, which enhances flexibility and management of alert rules through ConfigMaps. Additionally, you've set up a Prometheus pod by passing a custom prometheus.yml file through a values file, enabling effective monitoring of your applications and services. For further customization and deployment options, consult the Helm chart documentation or the official Prometheus docs.</p> <p>Feel free to modify the examples and instructions to fit your specific use case!</p>"},{"location":"runbooks/ec2-restart/","title":"Restart EC2 Instance","text":""},{"location":"runbooks/ec2-restart/#purpose","title":"Purpose","text":"<p>This runbook details the steps required to restart an EC2 instance in the AWS environment.</p>"},{"location":"runbooks/ec2-restart/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS IAM user with sufficient permissions to stop and start EC2 instances.</li> <li>AWS CLI installed and configured with appropriate credentials.</li> </ul>"},{"location":"runbooks/ec2-restart/#steps","title":"Steps","text":"<p>Identify the EC2 Instance</p> <ul> <li>Log in to the AWS Management Console.</li> <li>Navigate to the EC2 Dashboard.</li> <li>Identify the instance to be restarted. Note its Instance ID and Instance State.</li> </ul> <p>Check Instance Status</p> <ul> <li>Ensure the instance is in a state that can be restarted (e.g., it should be in the running state).</li> </ul> <p>Stop the EC2 Instance</p> <ul> <li> <p>Use AWS CLI to stop the instance:  </p> <p>aws ec2 stop-instances --instance-ids  -   for the instance to reach the \"stopped\" state. <p>Start the EC2 Instance</p> <ul> <li> <p>Use AWS CLI to start the instance:  </p> <p>aws ec2 start-instances --instance-ids  -   for the instance to reach the \"running\" state. <p>Verify the Instance State</p> <ul> <li>Ensure the instance is back to the \"running\" state.</li> <li>Check that all services are up and running on the instance.</li> </ul> <p>Notifications</p> <ul> <li>Notify the relevant team members or stakeholders that the EC2 instance has been restarted.</li> </ul>"},{"location":"runbooks/ec2-restart/#post-conditions","title":"Post-conditions","text":"<ul> <li>The EC2 instance should be in the running state.</li> <li>Services hosted on the instance should be operational.</li> </ul>"},{"location":"runbooks/ec2-restart/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If the instance does not stop or start as expected, check for AWS service issues or IAM permission issues.</li> <li>Review instance logs and metrics in the AWS Management Console for any errors or unusual activity.</li> </ul>"},{"location":"runbooks/eks-restart/","title":"Restart  EKS  Cluster","text":""},{"location":"runbooks/eks-restart/#purpose","title":"Purpose","text":"<p>This  runbook  details  the  steps  required  to  safely  restart  an  Amazon  EKS  cluster.</p>"},{"location":"runbooks/eks-restart/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS  IAM  user  with  sufficient  permissions  to  manage  EKS  clusters.   </li> <li>AWS  CLI  installed  and  configured  with  appropriate  credentials.  </li> <li>kubectl  installed  and  configured  to  interact  with  your  EKS  cluster.</li> </ul>"},{"location":"runbooks/eks-restart/#steps","title":"Steps","text":"<p>1.  Identify  the  EKS  Cluster</p> <ul> <li>Log  in  to  the  AWS  Management  Console.   </li> <li>Navigate  to  the  EKS  Dashboard.  </li> <li>Identify  the  cluster  to  be  restarted.  Note  its  Cluster  Name  and  Region.</li> </ul> <p>2.  Drain  Nodes  in  the  Cluster</p> <ul> <li>Use  kubectl  to  drain  each  node  to  safely  evict  all  pods,  ignoring  daemonsets  and  deleting  local  data.  </li> <li>Repeat  for  each  node  in  the  cluster.</li> </ul> <p>3.  Delete  Worker  Nodes  (Optional)</p> <ul> <li>If  you  need  to  terminate  worker  nodes,  use  the  AWS  CLI  to  terminate  the  instances.  </li> <li>Ensure  new  worker  nodes  are  launched  automatically  if  configured  with  an  Auto  Scaling  Group.</li> </ul> <p>4.  Restart  the  EKS  Control  Plane</p> <ul> <li>Restarting  the  control  plane  involves  stopping  and  starting  the  EKS  cluster  through  the  AWS  Management  Console.  </li> <li>In  the  EKS  Dashboard,  select  the  cluster  to  restart,  choose  Stop,  and  then  Start  to  restart  the  control  plane.</li> </ul> <p>5.  Re-join  Worker  Nodes  to  the  Cluster</p> <ul> <li>Ensure  that  worker  nodes,  either  existing  or  newly  launched,  are  re-joined  to  the  cluster. </li> <li>Use  kubectl  to  uncordon  the  nodes. </li> <li>Repeat  for  each  node  in  the  cluster.</li> </ul> <p>6.  Verify  Cluster  State</p> <ul> <li>Ensure  that  all  nodes  are  in  a  ready  state  using  kubectl.</li> <li>Check  the  status  of  all  pods  to  ensure  they  are  running  correctly.</li> </ul> <p>7.  Notifications -   Notify  relevant  team  members  or  stakeholders  that  the  EKS  cluster  has  been  restarted.</p>"},{"location":"runbooks/eks-restart/#post-conditions","title":"Post-conditions","text":"<ul> <li>The  EKS  cluster  should  be  fully  operational.</li> <li>All  nodes  should  be  in  a  ready  state.</li> <li>All  services  and  pods  should  be  running  correctly.</li> </ul>"},{"location":"runbooks/velero-eks/","title":"Velero Backup for EKS","text":""},{"location":"runbooks/velero-eks/#purpose","title":"Purpose","text":"<p>This runbook details the steps required to perform backups using Velero.</p>"},{"location":"runbooks/velero-eks/#prerequisites","title":"Prerequisites","text":"<ul> <li> <p>Velero installed and configured in your EKS cluster.</p> </li> <li> <p>AWS CLI installed and configured with appropriate credentials.</p> </li> <li> <p>BackupStorageLocation and VolumeSnapshotLocation resources configured in Velero.</p> </li> </ul>"},{"location":"runbooks/velero-eks/#steps","title":"Steps","text":"<p>1. Identify Backup Storage Location</p> <ul> <li> <p>Ensure that a BackupStorageLocation is configured for AWS S3 or your desired storage provider (Azure, GCP etc).</p> </li> <li> <p>Verify the configuration using:</p> <pre><code>velero backup-location get\n</code></pre> </li> </ul> <p>2. Identify Volume Snapshot Location</p> <ul> <li> <p>Ensure that a VolumeSnapshotLocation is configured for your desired snapshot provider.</p> </li> <li> <p>Verify the configuration using:</p> <pre><code>velero snapshot-location get\n</code></pre> </li> </ul> <p>3. Create a Backup</p> <ul> <li> <p>Create a backup using the Velero CLI:</p> <pre><code>velero backup create &lt;backup-name&gt; --include-namespaces=&lt;namespace&gt; --wait\n</code></pre> </li> <li> <p>Replace <code>&lt;backup-name&gt;</code>  with your desired backup name and <code>&lt;namespace&gt;</code>  with the namespace you want to back up.</p> </li> </ul> <p>4. Monitor Backup Progress</p> <ul> <li> <p>Monitor the progress of the backup using:</p> <pre><code>velero backup describe &lt;backup-name&gt;\n</code></pre> </li> </ul> <p>5. Verify Backup Completion</p> <ul> <li> <p>Once the backup is complete, verify the status using:</p> <pre><code>velero backup describe &lt;backup-name&gt;\n</code></pre> </li> <li> <p>Check the status of the backup and ensure it is marked as <code>Completed</code>.</p> </li> </ul> <p>6. Schedule Backups (Optional)</p> <ul> <li> <p>If you want to schedule regular backups, create a schedule using:</p> <pre><code>velero schedule create &lt;schedule-name&gt; --schedule=&lt;cron-expression&gt; --include-namespaces=&lt;namespace&gt;\n</code></pre> </li> <li> <p>Replace <code>&lt;schedule-name&gt;</code>  with your desired schedule name, <code>&lt;cron-expression&gt;</code>  with the appropriate cron expression, and <code>&lt;namespace&gt;</code>  with the namespace to back up.</p> </li> </ul> <p>7. Restore from Backup</p> <ul> <li> <p>To restore from a backup, use the Velero CLI:</p> <pre><code>velero restore create &lt;restore-name&gt; --from-backup=&lt;backup-name&gt; --wait\n</code></pre> </li> <li> <p>Replace <code>&lt;restore-name&gt;</code>  with your desired restore name and <code>&lt;backup-name&gt;</code>  with the name of the backup to restore from.</p> </li> </ul> <p>8. Verify Restore Completion</p> <ul> <li> <p>Monitor the progress of the restore using:</p> <pre><code>velero restore describe &lt;restore-name&gt;\n</code></pre> </li> <li> <p>Check the status of the restore and ensure it is marked as <code>Completed</code>.</p> </li> </ul>"},{"location":"runbooks/velero-eks/#post-conditions","title":"Post-conditions","text":"<ul> <li> <p>The backup should be successfully created and stored in the configured storage location.</p> </li> <li> <p>The restore should be successfully completed, and the data should be available in the specified namespace.</p> </li> </ul>"},{"location":"runbooks/velero-eks/#troubleshooting","title":"Troubleshooting","text":"<ul> <li> <p>If backups fail, check the Velero logs for errors using:</p> <pre><code>kubectl logs -n velero &lt;velero-pod-name&gt;\n</code></pre> </li> <li> <p>Ensure that the BackupStorageLocation and VolumeSnapshotLocation resources are correctly configured.</p> </li> <li> <p>Verify that the storage provider credentials are valid and have the necessary permissions.</p> </li> </ul>"},{"location":"weatherapp/building_weather-app/","title":"Weather App","text":"<p>In this project we will be using a simple application which we will refer to as \"Weather App\", an application that provides real-time weather information based on the city/location the user inputs. </p> <p>This project utilizes the OpenWeatherMap API to fetch weather data and presents it in a user-friendly interface.</p>"},{"location":"weatherapp/building_weather-app/#obtaining-an-api-key","title":"Obtaining an API Key","text":"<ol> <li>Go to the OpenWeatherMap website.</li> <li>Sign up for a free account if you don\u2019t have one.</li> <li>After logging in, navigate to the API section and generate an API key.</li> </ol>"},{"location":"weatherapp/building_weather-app/#running-with-docker","title":"Running with Docker","text":"<p>To run the application using Docker, you can pass your API key as an environment variable:</p> <ol> <li>Build the Docker image: <pre><code>    docker build -t weather-app .\n</code></pre></li> <li> <p>Run the Docker container, replacing your_api_key_here with your actual API key, and set your_metric_user_here and your_metric_password_here with your actual username and password.</p> <p>This configuration allows Prometheus or exporters to access the metrics URL: <pre><code>    docker run -d \\\n        -e API_KEY=your_api_key_here \\\n        -e METRIC_USER=your_metric_user_here\\\n        -e METRIC_PASSWORD=your_metric_password_here\\\n        -p 3000:3000 weather-app\n</code></pre> 3. Open your browser and go to http://localhost:8080 to access the app.</p> </li> </ol>"},{"location":"weatherapp/building_weather-app/#health-check","title":"Health Check","text":"<p>The web application includes a health check endpoint to monitor its status. This is useful for ensuring that the application is running smoothly and can help with automated monitoring systems.</p>"},{"location":"weatherapp/building_weather-app/#endpoint","title":"Endpoint","text":"<ul> <li>URL: <code>/health</code></li> <li>Method: GET</li> </ul>"},{"location":"weatherapp/building_weather-app/#response","title":"Response","text":"<p>When you send a GET request to the <code>/health</code> endpoint, the application will respond with a JSON object containing the current health status. </p>"},{"location":"weatherapp/building_weather-app/#weather-app-helm-chart","title":"Weather App Helm Chart","text":"<p>This section provides instructions on how to deploy the Weather App using a Helm chart. The Weather App is a simple application that provides weather data based on user input.</p>"},{"location":"weatherapp/building_weather-app/#prerequisites","title":"Prerequisites","text":"<ol> <li>Kubernetes cluster up and running.</li> <li>Helm installed on your local machine.</li> <li>Access to the Docker registry where the weather app image is stored.</li> </ol>"},{"location":"weatherapp/building_weather-app/#deployment-steps","title":"Deployment Steps","text":"<ol> <li>Add the Helm Chart Repository If you have not already added the repository for the Weather App, do so by running:</li> </ol> <pre><code>helm repo add weather-app-repo &lt;repository-url&gt;\nhelm repo update\n</code></pre> <ol> <li>Configure the Values Before deploying the Helm chart, you need to configure a few important variables. You can create a values.yaml file to specify these settings. Below are the variables you need to configure:</li> </ol> <pre><code>docker:\n  registry64: \"&lt;your-docker-registry-url&gt;\"  # URL of the Docker registry where the weather app image is stored.\n\napikey: \"&lt;your-api-key&gt;\"  # API key for accessing weather data.\n\nmetrics:\n  user: \"&lt;your-metrics-username&gt;\"  # Username for Basic Auth for the \"/metrics\" endpoint.\n  password: \"&lt;your-metrics-password&gt;\"  # Password for Basic Auth for the \"/metrics\" endpoint.\n</code></pre> <p>Make sure to replace the placeholder values with your actual configuration.</p> <ol> <li>Install the Helm Chart To deploy the Weather App using your customized values.yaml, run the following command:</li> </ol> <pre><code>helm install weather-app weather-app-repo/weather-app -f values.yaml\n</code></pre> <ol> <li>Verify the Deployment After installation, you can check the status of your deployment:</li> </ol> <pre><code>kubectl get all -l app=weather-app\n</code></pre> <ol> <li> <p>Access the Weather App Depending on your Kubernetes setup, you may need to expose the service to access the Weather App. You can use kubectl port-forward or configure an Ingress resource.</p> </li> <li> <p>Update the Deployment If you need to update any configurations or the Docker image, modify your values.yaml file and run:</p> </li> </ol> <pre><code>helm upgrade weather-app weather-app-repo/weather-app -f values.yaml\n</code></pre> <ol> <li>Uninstall the Helm Chart To uninstall the Weather App, run:</li> </ol> <pre><code>helm uninstall weather-app\n</code></pre>"},{"location":"weatherapp/building_weather-app/#conclusion","title":"Conclusion","text":"<p>You have successfully deployed the Weather App using the Helm chart. Make sure to monitor the application and adjust the configurations as needed. For any issues, consult the logs or reach out for support.</p> <p>Happy weather forecasting! \ud83c\udf24\ufe0f</p>"},{"location":"weatherapp/building_weather-app/#weather-app-helm-chart_1","title":"Weather App Helm Chart","text":"<p>This section provides instructions on how to deploy the Weather App using a Helm chart. The Weather App is a simple application that provides weather data based on user input.</p>"},{"location":"weatherapp/building_weather-app/#prerequisites_1","title":"Prerequisites","text":"<ol> <li>Kubernetes cluster up and running.</li> <li>Helm installed on your local machine.</li> <li>Access to the Docker registry where the weather app image is stored.</li> </ol>"},{"location":"weatherapp/building_weather-app/#deployment-steps_1","title":"Deployment Steps","text":"<ol> <li>Add the Helm Chart Repository If you have not already added the repository for the Weather App, do so by running:</li> </ol> <pre><code>helm repo add weather-app-repo &lt;repository-url&gt;\nhelm repo update\n</code></pre> <ol> <li>Configure the Values Before deploying the Helm chart, you need to configure a few important variables. You can create a values.yaml file to specify these settings. Below are the variables you need to configure:</li> </ol> <pre><code>docker:\n  registry64: \"&lt;your-docker-registry-url&gt;\"  # URL of the Docker registry where the weather app image is stored.\n\napikey: \"&lt;your-api-key&gt;\"  # API key for accessing weather data.\n\nmetrics:\n  user: \"&lt;your-metrics-username&gt;\"  # Username for Basic Auth for the \"/metrics\" endpoint.\n  password: \"&lt;your-metrics-password&gt;\"  # Password for Basic Auth for the \"/metrics\" endpoint.\n</code></pre> <p>Make sure to replace the placeholder values with your actual configuration.</p> <ol> <li>Install the Helm Chart To deploy the Weather App using your customized values.yaml, run the following command:</li> </ol> <pre><code>helm install weather-app weather-app-repo/weather-app -f values.yaml\n</code></pre> <ol> <li>Verify the Deployment After installation, you can check the status of your deployment:</li> </ol> <pre><code>kubectl get all -l app=weather-app\n</code></pre> <ol> <li> <p>Access the Weather App Depending on your Kubernetes setup, you may need to expose the service to access the Weather App. You can use kubectl port-forward or configure an Ingress resource.</p> </li> <li> <p>Update the Deployment If you need to update any configurations or the Docker image, modify your values.yaml file and run:</p> </li> </ol> <pre><code>helm upgrade weather-app weather-app-repo/weather-app -f values.yaml\n</code></pre> <ol> <li>Uninstall the Helm Chart To uninstall the Weather App, run:</li> </ol> <pre><code>helm uninstall weather-app\n</code></pre>"},{"location":"weatherapp/building_weather-app/#conclusion_1","title":"Conclusion","text":"<p>You have successfully deployed the Weather App using the Helm chart. Make sure to monitor the application and adjust the configurations as needed. For any issues, consult the logs or reach out for support.</p> <p>Happy weather forecasting! \ud83c\udf24\ufe0f</p>"}]}